{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:11:38.667891Z",
     "start_time": "2024-06-07T03:11:11.522689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --upgrade --quiet  langchain langchain-community langchainhub langchain-chroma bs4"
   ],
   "id": "4aaa336aff2f6387",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:13:31.508416Z",
     "start_time": "2024-06-07T03:13:31.505077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "# import dotenv\n",
    "\n",
    "# dotenv.load_dotenv()"
   ],
   "id": "593bb539be32c925",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:13:33.533457Z",
     "start_time": "2024-06-07T03:13:33.077985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ],
   "id": "18945242e26685ca",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. Load, chunk and index the contents of the blog to create a retriever.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "# 2. Incorporate the retriever into a question-answering chain.\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ],
   "id": "208e1e515076eae2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:21:23.271961Z",
     "start_time": "2024-06-07T03:21:14.690499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 1. Load, chunk and index the contents of the blog to create a retriever.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "# 2. Incorporate the retriever into a question-answering chain.\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ],
   "id": "ea75c8b0f7d9813c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:21:32.904728Z",
     "start_time": "2024-06-07T03:21:28.547497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is Task Decomposition?\"})\n",
    "response[\"answer\"]"
   ],
   "id": "d8652df274a1887b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition involves breaking down a complex task into smaller and simpler steps to make it more manageable. This process helps agents or models plan ahead and tackle difficult tasks effectively by dividing them into more achievable sub-tasks. Various techniques like Chain of Thought and Tree of Thoughts are used to decompose tasks into multiple steps for better understanding and execution.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "30446edc04b424e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")"
   ],
   "id": "1073b30b602b338d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "该链将输入查询的改写添加到我们的检索器中，以便检索包含对话的上下文。",
   "id": "dc3404789f0586b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ],
   "id": "62b6fce462a753b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:33:02.004470Z",
     "start_time": "2024-06-07T03:32:54.559983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "question = \"What is Task Decomposition?\"\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=ai_msg_1[\"answer\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "second_question = \"What are common ways of doing it?\"\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "\n",
    "print(ai_msg_2[\"answer\"])"
   ],
   "id": "b5be2b07f28c6188",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common ways of extending the capabilities of LLMs through tool use include providing internet access for searches and information gathering, managing long-term memory effectively, utilizing GPT-3.5 powered agents for task delegation, and enabling file output for storing information. Additionally, performance evaluation techniques such as continuous self-review, constructive self-criticism, reflection on past decisions, and efficient task completion strategies can also enhance the overall performance of LLM-centered agents. Lastly, task decomposition methods involving LLM prompting, task-specific instructions, and human inputs can help in breaking down complex tasks into manageable steps for the LLM to process effectively.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "下面我们实现第二种方案的简单示例，聊天记录存储在一个简单的字典中。LangChain 管理与Redis和其他技术的内存集成，以提供更强大的持久性。\n",
    "\n",
    "实例RunnableWithMessageHistory为您管理聊天历史记录。它们接受带有键的配置（\"session_id\"默认情况下），该键指定要获取并添加到输入中的对话历史记录，并将输出附加到相同的对话历史记录。以下是一个例子："
   ],
   "id": "6e48da4f1ca25a40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:43:06.988183Z",
     "start_time": "2024-06-07T03:43:06.979317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ],
   "id": "c18a5dc95a13b744",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:43:13.675753Z",
     "start_time": "2024-06-07T03:43:09.449671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What is Task Decomposition?\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    },  # constructs a key \"abc123\" in `store`.\n",
    ")[\"answer\"]\n"
   ],
   "id": "c231b9dd2e0486e0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.tracers.core:Parent run 012d3da6-c546-46e2-9e78-9b12c22b7340 not found for run 8f1d56fd-ef63-434d-a94b-ebebe5882ab8. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. This process helps agents, like autonomous systems, plan and execute tasks more efficiently. It can be achieved by prompting models with specific instructions, such as guiding them to think step by step or by using human inputs.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:47:11.883825Z",
     "start_time": "2024-06-07T03:47:06.526413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\": \"What are common ways of doing it?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
    ")[\"answer\"]"
   ],
   "id": "434b7aa634ff59bd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.tracers.core:Parent run 97a20fa3-c9d2-4179-86e2-b42496478bde not found for run a82dba53-9f35-4251-be9a-2cb81790af68. Treating as a root run.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Common ways of extending the capabilities of language model agents include providing internet access for searches and information gathering, managing long-term memory effectively, utilizing GPT-3.5 powered agents for delegating simple tasks, and enabling file output for storing information. Performance evaluation involves continuously reviewing actions, self-critiquing behavior, reflecting on past decisions, and optimizing task completion efficiency. Task decomposition can be achieved through simple prompting by the language model, task-specific instructions, or human inputs to enhance problem-solving and decision-making processes.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:47:13.940259Z",
     "start_time": "2024-06-07T03:47:13.937602Z"
    }
   },
   "cell_type": "code",
   "source": "print(f'store:{store}')",
   "id": "e620442a2ff6c9d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store:{'abc123': InMemoryChatMessageHistory(messages=[HumanMessage(content='What is Task Decomposition?'), AIMessage(content='Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. This process helps agents, like autonomous systems, plan and execute tasks more efficiently. It can be achieved by prompting models with specific instructions, such as guiding them to think step by step or by using human inputs.'), HumanMessage(content='What are common ways of doing it?'), AIMessage(content='Common ways of extending the capabilities of language model agents include providing internet access for searches and information gathering, managing long-term memory effectively, utilizing GPT-3.5 powered agents for delegating simple tasks, and enabling file output for storing information. Performance evaluation involves continuously reviewing actions, self-critiquing behavior, reflecting on past decisions, and optimizing task completion efficiency. Task decomposition can be achieved through simple prompting by the language model, task-specific instructions, or human inputs to enhance problem-solving and decision-making processes.')])}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T03:47:45.350158Z",
     "start_time": "2024-06-07T03:47:45.346680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for message in store[\"abc123\"].messages:\n",
    "    if isinstance(message, AIMessage):\n",
    "        prefix = \"AI\"\n",
    "    else:\n",
    "        prefix = \"User\"\n",
    "\n",
    "    print(f\"{prefix}: {message.content}\\n\")"
   ],
   "id": "65653f23e9372574",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is Task Decomposition?\n",
      "\n",
      "AI: Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. This process helps agents, like autonomous systems, plan and execute tasks more efficiently. It can be achieved by prompting models with specific instructions, such as guiding them to think step by step or by using human inputs.\n",
      "\n",
      "User: What are common ways of doing it?\n",
      "\n",
      "AI: Common ways of extending the capabilities of language model agents include providing internet access for searches and information gathering, managing long-term memory effectively, utilizing GPT-3.5 powered agents for delegating simple tasks, and enabling file output for storing information. Performance evaluation involves continuously reviewing actions, self-critiquing behavior, reflecting on past decisions, and optimizing task completion efficiency. Task decomposition can be achieved through simple prompting by the language model, task-specific instructions, or human inputs to enhance problem-solving and decision-making processes.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://python.langchain.com/v0.2/assets/images/conversational_retrieval_chain-5c7a96abe29e582bc575a0a0d63f86b0.png",
   "id": "1fe7c90453885a7c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
